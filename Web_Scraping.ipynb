{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib\n",
    "\n",
    "from IPython.display import Image, display\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping IGN game review information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# After I checked how many pages for each game console, I create the below dict:\n",
    "platformDict = {'xbox-one': 275,'ps4': 425,'nintendo-switch':50,'wii-u':125}\n",
    "furl = 'http://www.ign.com/reviews/games/'\n",
    "lurl = '?sortBy=reviewDate&sortOrder=desc&genre=&startIndex='\n",
    "\n",
    "# Data that I would like to get:\n",
    "gameCover = []\n",
    "gameTitle = []\n",
    "gamePlatform = []\n",
    "gameGenre = []\n",
    "gameRating = []\n",
    "gamePhrase = []\n",
    "gameReview = []\n",
    "\n",
    "for x,y in platformDict.iteritems():\n",
    "    url = furl+x+lurl\n",
    "    pages = y\n",
    "    for i in range(0,pages,25):\n",
    "        surl = url + str(i)\n",
    "        print surl\n",
    "        r = urllib.urlopen(surl).read()\n",
    "        soup = BeautifulSoup(r, \"lxml\")\n",
    "        tr = soup.find_all(\"div\",  class_ = \"gameList-game\")\n",
    "        for x in tr:\n",
    "            img = x.find('img') \n",
    "            # Only get review with game cover\n",
    "            if img <> None:\n",
    "                gameCover.append(img.get('src'))\n",
    "                gameTitle.append(x.find('div', class_ = \"game-title\").find('a').text.strip())\n",
    "                gamePlatform.append(x.find('div', class_ = \"game-title\").find('span').text.strip())\n",
    "                gameGenre.append(x.find('span', class_ = \"game-genre\").string.replace(\" \", \"\").strip())\n",
    "                gameRating.append(float(x.find('div', class_ = \"scoreBox\").find('a').text.split('\\n')[1]))\n",
    "                gamePhrase.append(x.find('div', class_ = \"scoreBox\").find('a').text.split('\\n')[2])\n",
    "                gameReview.append(x.find('div', class_ = \"scoreBox\").find('a').get('href'))\n",
    "\n",
    "                \n",
    "columns = {'gameCover': gameCover,\n",
    "           'gameTitle': gameTitle,\n",
    "           'gamePlatform': gamePlatform,\n",
    "           'gameGenre': gameGenre,\n",
    "           'gameRating':gameRating,\n",
    "           'gamePhrase':gamePhrase,\n",
    "           'gameReview':gameReview\n",
    "          }\n",
    "df_IGN = pd.DataFrame(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping IGN full game review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# After got game review link\n",
    "# then scrap the full game review\n",
    "author = []\n",
    "reviews = []\n",
    "reviewLink = []\n",
    "\n",
    "for x in df_IGN.gameReview.unique()[:]:\n",
    "    surl = x\n",
    "    r = urllib.urlopen(surl).read()\n",
    "    soup = BeautifulSoup(r, \"lxml\")\n",
    "    review = ''\n",
    "    print surl\n",
    "    reviewLink.append(x)\n",
    "    # Some old review doesn't show author name\n",
    "    if soup.find('span',class_ = \"author-name\") <> None:\n",
    "        author.append(soup.find('span',class_ = \"author-name\").text.strip())\n",
    "    else: \n",
    "        author.append('')    \n",
    "    tr = soup.find_all(\"p\")\n",
    "    if tr <> None:\n",
    "        for y in tr[:-2]:            \n",
    "            review += ' ' + y.text.strip()\n",
    "        reviews.append(review)\n",
    "    else:\n",
    "        reviews.append('')\n",
    "        \n",
    "columns = {'author': author,\n",
    "           'reviews': reviews,\n",
    "           'reviewLink': reviewLink\n",
    "         }\n",
    "df_reviews = pd.DataFrame(columns)\n",
    "df_reviews.head()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Game Cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df_IGN.sort_values('gamePlatformAlias', ascending = True).groupby('gameReview').first()\n",
    "poster_path = \"gameCover/\"\n",
    "for x,y in df.sort_values('gameReviewID').iterrows():\n",
    "    print y.gameReviewID,y.gameCover\n",
    "    urllib.urlretrieve(y.gameCover, poster_path + str(y.gameReviewID) + \".jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get IGN review user's top comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping user's comment isn't easy  \n",
    "Its all loaded by Javascript   \n",
    "cant just simply use urllib.urlopen(surl).read()  \n",
    "In this case, wil try 'selenium' to actullay open a browser and scrap the comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IGN_link = df_IGN.gameReview.drop_duplicates().sort_values(ascending = False).tolist()\n",
    "ign_comment = []\n",
    "link = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome('chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## IGN use different class name on differnt game review\n",
    "# check_loading = 'fyre-stream-sort-top-comments'\n",
    "# check_loading = 'fyre-stream-sort-options'\n",
    "check_loading = 'fyre-stream-more-container'\n",
    "\n",
    "while len(IGN_link) > 0:\n",
    "    url = IGN_link[0]\n",
    "    print url\n",
    "    browser.get(url)\n",
    "    browser.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    print 'loading.......comment........'\n",
    "    element = wait.until(EC.element_to_be_clickable((By.CLASS_NAME, check_loading)))\n",
    "    element.click()\n",
    "    comments = browser.find_elements_by_class_name('fyre-comment')\n",
    "    print len(comments)\n",
    "    gameComment = []\n",
    "    if len(comments) > 0:\n",
    "        for x in comments:\n",
    "            gameComment.append(x.text)\n",
    "    ign_comment.append(gameComment)\n",
    "    link.append(url)\n",
    "    IGN_link.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = {'ign_comment': ign_comment, 'link': link}\n",
    "df_IGN_Comment = pd.DataFrame(columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
